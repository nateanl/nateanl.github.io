{"meta":{"title":"Zhaoheng Ni","subtitle":null,"description":"Zhaoheng Ni's blog","author":"Zhaoheng Ni","url":"nateanl.github.io","root":"/"},"pages":[{"title":"About","date":"2020-03-05T08:41:00.710Z","updated":"2020-03-05T08:41:00.710Z","comments":true,"path":"about/index.html","permalink":"nateanl.github.io/about/index.html","excerpt":"","text":""},{"title":"Project","date":"2020-03-04T08:59:48.449Z","updated":"2020-03-04T08:59:48.449Z","comments":true,"path":"project/index.html","permalink":"nateanl.github.io/project/index.html","excerpt":"","text":""},{"title":"","date":"2020-02-10T12:28:06.130Z","updated":"2019-08-26T00:04:31.784Z","comments":false,"path":"publications/index.html","permalink":"nateanl.github.io/publications/index.html","excerpt":"","text":"Zhaoheng Ni, Rutuja Ubale, Yao Qian, Michael Mandel, Su-Youn Yoon, Abhinav Misra, and David Suendermann-Oeft. “Unusable Spoken Response Detection with BLSTM Neural Networks.” ISCSLP 2018 Weicheng Ma, Kai Cao, Zhaoheng Ni, Peter Chin, and Xiang Li. “Sound Signal Processing with Seq2Tree Network.” In Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC-2018). 2018. Zhaoheng Ni, Ahmet Cem Yuksel, Xiuyan Ni, Michael I. Mandel, and Lei Xie. “Confused or not confused?: Disentangling brain activity from eeg data using bidirectional lstm recurrent neural networks.” In Proceedings of the 8th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics, pp. 241-246. ACM, 2017. Weicheng Ma, Kai Cao, Zhaoheng Ni, Xiuyan Ni, and Sang Chin. “Sound signal processing based on seq2tree network.” In Proceedings of Interspeech workshop on Vocal Interactivity in-andbetween Humans, Animals and Robots. 2017. Yan Xu, Ji Hua, Zhaoheng Ni, Qinlang Chen, Yubo Fan, Sophia Ananiadou, I. Eric, Chao Chang, and Junichi Tsujii. “Anatomical entity recognition with a hierarchical framework augmented by external resources.” PloS one 9, no. 10 (2014): e108396."},{"title":"Tags","date":"2020-03-04T08:59:48.450Z","updated":"2020-03-04T08:59:48.450Z","comments":true,"path":"tags/index.html","permalink":"nateanl.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Onssen: an open-source speech separation and enhancement library","slug":"onssen","date":"2020-03-05T13:52:16.000Z","updated":"2020-03-05T14:02:34.620Z","comments":true,"path":"2020/03/05/onssen/","link":"","permalink":"nateanl.github.io/2020/03/05/onssen/","excerpt":"","text":"We are happy to release onssen (pronounced as 温泉, the Japanese spring), an PyTorch-based deep learning library for speech enhancement and speech separation. Feel free to fork it on GitHub and add your models to it :) It supports the following separation models: Deep Clustering Chimera Net Chimera++ Phase Estimation Network Speech Enhancement with Restoration Layers Supported Dataset Wsj0-2mix (http://www.merl.com/demos/deep-clustering) Daps (https://archive.org/details/daps_dataset) Edinburgh-TTS (https://datashare.is.ed.ac.uk/handle/10283/2791) Requirements PyTorch LibRosa NumPy UsageYou can simply use the existing config JSON file or customize your config file to train the enhancement or separation model. 1python train.py -c configs/dc_config.json CitingIf you plan to use onssen for your research project, please cite one of the following bibtex citations: @inproceedings {onssen, author = {Zhaoheng Ni and Michael Mandel}, title = &quot;ONSSEN: An Open-source Speech Separation and Enhancement Library&quot;, publisher = &quot;under review&quot;, year = 2019 } @Misc{onssen, author = {Zhaoheng Ni and Michael Mandel}, title = &quot;ONSSEN: An Open-source Speech Separation and Enhancement Library&quot;, howpublished = {\\url{https://github.com/speechLabBcCuny/onssen}}, year = {2019} }","categories":[],"tags":[{"name":"dnn","slug":"dnn","permalink":"nateanl.github.io/tags/dnn/"}]},{"title":"Mask-dependent phase estimation for monaural speaker separation","slug":"speech-separation-demo","date":"2019-04-25T14:06:25.000Z","updated":"2020-03-05T13:47:03.214Z","comments":true,"path":"2019/04/25/speech-separation-demo/","link":"","permalink":"nateanl.github.io/2019/04/25/speech-separation-demo/","excerpt":"Speech separation refers to the task of isolating speech of interest in a multi-talker environment.","text":"Speech separation refers to the task of isolating speech of interest in a multi-talker environment. Most methods apply real-valued Time-Frequency (T-F) Masks to the Short-time Fourier Transform (STFT) of the noisy speech to get the estimated clean speech. The Idea Ratio Mask (IRM) is defined as IRM = \\frac{|S|}{|X|},where $|S|$ and $|Y|$ is the magnitude of clean speech and noisy speech respectively. The mask value is close to 1 if the T-F bin is dominated by the speaker, 0 otherwise. Since the clean STFT estimate is constructed by $IRM \\odot X$, there exists unavoidable phase difference in the masking method. We propose a novel phase estimation method which estimates the phase based on the T-F mask. Now the code is included in the onssen library. To evaluate the separation performance of our method, we compare our results with recent published ones including: Deep Clustering Chimera++ Network with MSA loss function Chimera++ Network with tPSA loss function Here are the separation demos for different methods. The testing utterance is from WSJ0-2mix dataset. Mixture Utterance tt/mix/050a0508_1.4465_22gc0102_-1.4465.wav Separation Results of different models(Swipe left to listen to the audios) Model Average SDRSpeaker 1 Speaker 2 Deep Clustering 9.2 dB Chimera++ MSA 10.2 dB Chimera++ tPSA 10.3 dB Phase Estimation 13.6 dB Clean Reference 301 dB (basically $+\\infty$) ReferencesHershey, John R., Zhuo Chen, Jonathan Le Roux, and Shinji Watanabe. “Deep clustering: Discriminative embeddings for segmentation and separation.” In 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 31-35. IEEE, 2016.Yu, Dong, Morten Kolbæk, Zheng-Hua Tan, and Jesper Jensen. “Permutation invariant training of deep models for speaker-independent multi-talker speech separation.” In 2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 241-245. IEEE, 2017.Wang, Zhong-Qiu, Jonathan Le Roux, and John R. Hershey. “Alternative objective functions for deep clustering.” In 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 686-690. IEEE, 2018.Wang, Zhong-Qiu, Jonathan Le Roux, DeLiang Wang, and John R. Hershey. “End-to-end speech separation with unfolded iterative phase reconstruction.” arXiv preprint arXiv:1804.10204 (2018).Paszke, Adam, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. “Automatic differentiation in pytorch.” (2017).Raffel, Colin, Brian McFee, Eric J. Humphrey, Justin Salamon, Oriol Nieto, Dawen Liang, Daniel PW Ellis, and C. Colin Raffel. “mir_eval: A transparent implementation of common MIR metrics.” In In Proceedings of the 15th International Society for Music Information Retrieval Conference, ISMIR. 2014.McFee, Brian, Colin Raffel, Dawen Liang, Daniel PW Ellis, Matt McVicar, Eric Battenberg, and Oriol Nieto. “librosa: Audio and music signal analysis in python.” In Proceedings of the 14th python in science conference, pp. 18-25. 2015.","categories":[],"tags":[{"name":"dnn","slug":"dnn","permalink":"nateanl.github.io/tags/dnn/"}]},{"title":"Word2vec, skip-gram, and negative sampling","slug":"word2vec","date":"2019-02-25T15:58:49.000Z","updated":"2020-03-05T14:14:49.924Z","comments":true,"path":"2019/02/25/word2vec/","link":"","permalink":"nateanl.github.io/2019/02/25/word2vec/","excerpt":"Though it’s already 9102, I stii want to talk a little about word2vec…","text":"Though it’s already 9102, I stii want to talk a little about word2vec… What is word2vec?Linear layer VS Embedding layerSkip-gram ModelNegative SamplingHow to choose negative words?Is Softmax really useful for Skip-gram model?To be continued…","categories":[],"tags":[{"name":"nlp","slug":"nlp","permalink":"nateanl.github.io/tags/nlp/"}]},{"title":"Build neural networks from scratch","slug":"neural-nets","date":"2019-02-13T01:45:40.000Z","updated":"2020-03-05T01:38:43.337Z","comments":true,"path":"2019/02/13/neural-nets/","link":"","permalink":"nateanl.github.io/2019/02/13/neural-nets/","excerpt":"Recently I read a post by Denny Britz about implementing a neural network from scratch in Python. I was pretty inspired by it. I still remember the days when I tried to study NN and it took me a bunch of hours to understand the gradients, chain rule, back-propagation, and so on. So it’s good to write a “Neural-Net for Baby” (NB) post to help myself understand it better. Okay, let’s start with a single-layer single-output neural net. We can regard the model as a linear regression model. o = \\sigma(\\sum_{i}^{N}w_ix_i + b)","text":"Recently I read a post by Denny Britz about implementing a neural network from scratch in Python. I was pretty inspired by it. I still remember the days when I tried to study NN and it took me a bunch of hours to understand the gradients, chain rule, back-propagation, and so on. So it’s good to write a “Neural-Net for Baby” (NB) post to help myself understand it better. Okay, let’s start with a single-layer single-output neural net. We can regard the model as a linear regression model. o = \\sigma(\\sum_{i}^{N}w_ix_i + b) $x$ is an N $\\times$ 1 input vector, $w$ is an N $\\times$ 1 weight vector, and $b$ is a bias scalar. $\\sigma$ is an activation function (I will talk about it later). Think in a geometry way, $w$ is the transformation matrix which projects the vector $x$ to a 1-D space. $b$ is a shift scalar (or a vector in multi-output net) which does linear-shift in the new space. Imagine you are playing golf, there are two holes: A and B. There are two kinds of balls: red and black. The golf club is the neural network. Every time you swing the club, the red ball will always fall into hole A, while the black ball will always fall into hole B. Some people tend to explain the weight value as the importance of the input feature value. Well, what if the feature value is negative and the weight is negative too? It doesn’t mean anything if the weight value is 0 also. Updating the weights is updating the bases of the hyperspace where the input vector is projected to. Back PropagationNow we know the neural network does projection (linear way or non-linear way). But how to train the network, to make it useful? Start with a simple example: o = axif $x$ is 1, $y$ is 2, $a$ is 1. So $o$ is 1. However, we want the result to be as close to $y$ as possible. So there is a difference between the output $o$ and the target $y$. We use mean square error as the loss function to compute the loss: L = (y-o)^2The gradient is $\\frac{\\partial L}{\\partial o}$ which is $2(o-y)$ which is -2. This means o needs to be larger to make the gradient decrease. Since we want to update $a$, we need to compute the gradient of a: \\frac{\\partial L}{\\partial a} = \\frac{\\partial L}{\\partial o} \\times \\frac{\\partial o}{\\partial a} = 2(o-y)xSo the gradient for $a$ is -2, and we can update it by this formula: a = a - \\eta \\frac{\\partial L}{\\partial a}$\\eta$ is called the learning rate. We want to iteratively make small changes on the weight so that the output will finally be close to the target. Set $\\eta$ to be 0.1, the updated $a$ will be 1.2. The new output $o$ will be 1.2. The new loss will be 0.64, which is smaller than before! After several iterations, we can make the output close to the target. Multi-Layer NetworkIf the neural networks has more than one layer, how can we train the model? According to the chain rule, it is easy AF. I really like to describe it in a matrix way because you can see how beautiful the formula is. But let’s start with this example: o_2 = W_2(W_1x+b_1)+b_2o_1 = W_1x+b_1$x$ is a $M$ dimensional vector. $W_1$ is a $M \\times N$ matrix, $W_2$ is a $N \\times K$ matrix, $b_1$ is a $N$ dimensional vector, and $b_2$ is a $K$ dimensional vector. The loss function is still mean square error: L = (y-o_2)^2The gradient for $W_2$ is: \\begin{gathered} \\frac{\\partial L}{\\partial W_2^{n,k}} &= &\\frac{\\partial L}{\\partial o_2^k} \\frac{\\partial o_2^k}{\\partial W_2^{n,k}}\\\\ &= &2(o_2^k-y^k)o_1^n \\end{gathered}$n$ is the index of $o_1$. $k$ is the index of $o_2$. So the gradient of $W_2$ is a $N\\times K$ matrix: \\frac{\\partial L}{\\partial W_2} = 2 o_1^T\\times(o_2-y)The gradient for $W_1$ is: \\begin{gathered} \\frac{\\partial L}{\\partial W_1^{m,n}} &=&\\sum_k{\\frac{\\partial L}{\\partial o_2^k}} \\frac{\\partial o_2^k}{\\partial o_1^n} \\frac{\\partial o_i^n}{\\partial W_1^{m,n}}\\\\ &=&\\sum_k{2(o_2^k-y^k)W_2^{n,k}} x^m \\end{gathered}It can also be transformed to a matrix form: \\frac{\\partial L}{\\partial W_1} =2x^T(o_2-y)W_2^TAfter we got these gradient matrix, we can update those weights by using the back-propagation method. In Python you can just apply numpy to do it. W_1 = W_1 - \\eta \\frac{\\partial L}{\\partial W_1} = W_1 - 2\\eta x^T(o_2-y)W_2^TSo, in this way, we can build our neural network model by using pure Python! The only problem is whenever we create a new model, we have to create a new backward function which contains a bunch of redundant codes. Chainer is the first framework which applies the “autograd”: automatic differentiation method to calculate the gradients automatically. I won’t recommend implementing such “autograd” things from scratch (There is a Chinese slang: 人生苦短，我用PyTorch ). But it is a good start to follow Denny’s notebook and build a simple two-layer neural network from scratch, and you can understand the idea of NN in a mathematical way.","categories":[],"tags":[{"name":"dnn","slug":"dnn","permalink":"nateanl.github.io/tags/dnn/"},{"name":"pytorch","slug":"pytorch","permalink":"nateanl.github.io/tags/pytorch/"}]},{"title":"Latex Test","slug":"latex","date":"2018-12-20T17:45:34.000Z","updated":"2020-03-05T01:14:33.178Z","comments":true,"path":"2018/12/21/latex/","link":"","permalink":"nateanl.github.io/2018/12/21/latex/","excerpt":"","text":"e^{i\\pi} + 1 = 0","categories":[],"tags":[{"name":"latex","slug":"latex","permalink":"nateanl.github.io/tags/latex/"}]}]}